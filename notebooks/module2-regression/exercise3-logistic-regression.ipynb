{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Module 2 - Exercise 3: Logistic Regression for Classification\n\n<a href=\"https://colab.research.google.com/github/jumpingsphinx/jumpingsphinx.github.io/blob/main/notebooks/module2-regression/exercise3-logistic-regression.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n\n## Learning Objectives\n\nBy the end of this exercise, you will be able to:\n\n- Implement logistic regression from scratch\n- Understand the sigmoid function and its properties\n- Compute logistic loss (binary cross-entropy)\n- Use gradient descent for optimization\n- Interpret probabilities and make predictions\n- Evaluate classification performance with various metrics\n\n## Prerequisites\n\n- Completion of Exercises 1 and 2\n- Understanding of classification problems\n- Familiarity with probability concepts\n\n## Setup\n\nRun this cell first to import required libraries:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer, load_iris, load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression as SklearnLogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: The Sigmoid Function\n",
    "\n",
    "### Background\n",
    "\n",
    "The sigmoid function maps any real-valued number to the range (0, 1):\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "Properties:\n",
    "- Output range: (0, 1)\n",
    "- $\\sigma(0) = 0.5$\n",
    "- $\\sigma(-\\infty) \\to 0$, $\\sigma(\\infty) \\to 1$\n",
    "- Derivative: $\\sigma'(z) = \\sigma(z)(1 - \\sigma(z))$\n",
    "\n",
    "### Exercise 1.1: Implement the Sigmoid Function\n",
    "\n",
    "**Task:** Implement sigmoid and visualize its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute sigmoid function.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    z : np.ndarray or float\n",
    "        Input value(s)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray or float\n",
    "        Sigmoid of input\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    # Formula: 1 / (1 + e^(-z))\n",
    "    return \n",
    "\n",
    "# Test sigmoid\n",
    "test_values = np.array([-10, -5, -1, 0, 1, 5, 10])\n",
    "sig_values = sigmoid(test_values)\n",
    "\n",
    "print(\"z values:       \", test_values)\n",
    "print(\"sigmoid(z):     \", sig_values)\n",
    "\n",
    "# Visualize sigmoid\n",
    "z = np.linspace(-10, 10, 200)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(z, sigmoid(z), linewidth=2)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='Decision boundary (0.5)')\n",
    "plt.axvline(x=0, color='g', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('sigmoid(z)')\n",
    "plt.title('Sigmoid Function')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "assert np.isclose(sigmoid(0), 0.5), \"sigmoid(0) should be 0.5\"\n",
    "assert sigmoid(-100) < 0.01, \"sigmoid(-large) should be close to 0\"\n",
    "assert sigmoid(100) > 0.99, \"sigmoid(large) should be close to 1\"\n",
    "print(\"\\n✓ Sigmoid function implemented correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Sigmoid Derivative\n",
    "\n",
    "**Task:** Implement the derivative of sigmoid (useful for backpropagation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(z):\n",
    "    \"\"\"\n",
    "    Compute derivative of sigmoid.\n",
    "    \n",
    "    d/dz sigmoid(z) = sigmoid(z) * (1 - sigmoid(z))\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    z : np.ndarray or float\n",
    "        Input value(s)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray or float\n",
    "        Derivative of sigmoid at z\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    sig = sigmoid(z)\n",
    "    return \n",
    "\n",
    "# Visualize sigmoid and its derivative\n",
    "z = np.linspace(-10, 10, 200)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(z, sigmoid(z), label='sigmoid(z)', linewidth=2)\n",
    "plt.plot(z, sigmoid_derivative(z), label=\"sigmoid'(z)\", linewidth=2)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('y')\n",
    "plt.title('Sigmoid and Its Derivative')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: Maximum derivative is 0.25 at z=0\")\n",
    "print(f\"sigmoid'(0) = {sigmoid_derivative(0):.4f}\")\n",
    "\n",
    "assert np.isclose(sigmoid_derivative(0), 0.25), \"sigmoid'(0) should be 0.25\"\n",
    "print(\"\\n✓ Sigmoid derivative implemented correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Binary Cross-Entropy Loss\n",
    "\n",
    "### Background\n",
    "\n",
    "For logistic regression, we use **binary cross-entropy** (log loss):\n",
    "\n",
    "$$J(\\mathbf{w}) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(h(\\mathbf{x}^{(i)})) + (1 - y^{(i)}) \\log(1 - h(\\mathbf{x}^{(i)}))]$$\n",
    "\n",
    "Where:\n",
    "- $h(\\mathbf{x}) = \\sigma(\\mathbf{w}^T \\mathbf{x})$ is the hypothesis\n",
    "- $y \\in \\{0, 1\\}$ is the true label\n",
    "\n",
    "### Exercise 2.1: Implement Binary Cross-Entropy\n",
    "\n",
    "**Task:** Implement the binary cross-entropy cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute binary cross-entropy loss.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : np.ndarray\n",
    "        True labels (0 or 1)\n",
    "    y_pred : np.ndarray\n",
    "        Predicted probabilities (between 0 and 1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Cross-entropy loss\n",
    "    \"\"\"\n",
    "    m = len(y_true)\n",
    "    \n",
    "    # Your code here\n",
    "    # Avoid log(0) by adding small epsilon\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = \n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Test the loss function\n",
    "y_true = np.array([1, 0, 1, 1, 0])\n",
    "y_pred_good = np.array([0.9, 0.1, 0.8, 0.95, 0.05])  # good predictions\n",
    "y_pred_bad = np.array([0.1, 0.9, 0.2, 0.1, 0.9])     # bad predictions\n",
    "\n",
    "loss_good = binary_cross_entropy(y_true, y_pred_good)\n",
    "loss_bad = binary_cross_entropy(y_true, y_pred_bad)\n",
    "\n",
    "print(f\"Loss with good predictions: {loss_good:.4f}\")\n",
    "print(f\"Loss with bad predictions:  {loss_bad:.4f}\")\n",
    "\n",
    "assert loss_good < loss_bad, \"Good predictions should have lower loss\"\n",
    "assert loss_good < 1.0, \"Good predictions should have loss < 1\"\n",
    "print(\"\\n✓ Binary cross-entropy implemented correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Logistic Regression with Gradient Descent\n",
    "\n",
    "### Background\n",
    "\n",
    "**Hypothesis:**\n",
    "$$h_\\mathbf{w}(\\mathbf{x}) = \\sigma(\\mathbf{w}^T \\mathbf{x})$$\n",
    "\n",
    "**Gradient:**\n",
    "$$\\frac{\\partial J}{\\partial w_j} = \\frac{1}{m} \\sum_{i=1}^{m} (h_\\mathbf{w}(\\mathbf{x}^{(i)}) - y^{(i)}) x_j^{(i)}$$\n",
    "\n",
    "Note: Same form as linear regression, but $h$ is now sigmoid!\n",
    "\n",
    "### Exercise 3.1: Implement Logistic Regression\n",
    "\n",
    "**Task:** Create a complete LogisticRegression class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000, random_state=None):\n",
    "        \"\"\"\n",
    "        Logistic Regression using gradient descent.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        learning_rate : float\n",
    "            Learning rate\n",
    "        n_iterations : int\n",
    "            Number of iterations\n",
    "        random_state : int\n",
    "            Random seed\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.random_state = random_state\n",
    "        self.weights = None\n",
    "        self.cost_history = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit logistic regression model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : np.ndarray\n",
    "            Training features (n_samples, n_features)\n",
    "        y : np.ndarray\n",
    "            Target labels (n_samples,) - binary (0 or 1)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        self\n",
    "        \"\"\"\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        m, n = X.shape\n",
    "        \n",
    "        # Add bias column\n",
    "        X_with_bias = np.c_[np.ones((m, 1)), X]\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.weights = np.random.randn(n + 1) * 0.01\n",
    "        \n",
    "        # Gradient descent\n",
    "        for iteration in range(self.n_iterations):\n",
    "            # Your code here\n",
    "            \n",
    "            # 1. Compute predictions (probabilities)\n",
    "            z = \n",
    "            predictions = \n",
    "            \n",
    "            # 2. Compute errors\n",
    "            errors = \n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            gradients = \n",
    "            \n",
    "            # 4. Update weights\n",
    "            self.weights = \n",
    "            \n",
    "            # 5. Compute and store cost\n",
    "            cost = binary_cross_entropy(y, predictions)\n",
    "            self.cost_history.append(cost)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predict probabilities.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : np.ndarray\n",
    "            Features\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            Predicted probabilities\n",
    "        \"\"\"\n",
    "        # Your code here\n",
    "        X_with_bias = \n",
    "        z = \n",
    "        return \n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Predict class labels.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : np.ndarray\n",
    "            Features\n",
    "        threshold : float\n",
    "            Decision threshold (default 0.5)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            Predicted class labels (0 or 1)\n",
    "        \"\"\"\n",
    "        # Your code here\n",
    "        probas = self.predict_proba(X)\n",
    "        return \n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculate accuracy.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : np.ndarray\n",
    "            Features\n",
    "        y : np.ndarray\n",
    "            True labels\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            Accuracy score\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)\n",
    "\n",
    "print(\"LogisticRegression class implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Test on Simple 2D Data\n",
    "\n",
    "**Task:** Test your implementation on synthetic 2D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate linearly separable 2D data\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "\n",
    "# Class 0: centered at (-2, -2)\n",
    "X_class0 = np.random.randn(n_samples // 2, 2) + np.array([-2, -2])\n",
    "y_class0 = np.zeros(n_samples // 2)\n",
    "\n",
    "# Class 1: centered at (2, 2)\n",
    "X_class1 = np.random.randn(n_samples // 2, 2) + np.array([2, 2])\n",
    "y_class1 = np.ones(n_samples // 2)\n",
    "\n",
    "# Combine\n",
    "X_2d = np.vstack([X_class0, X_class1])\n",
    "y_2d = np.hstack([y_class0, y_class1])\n",
    "\n",
    "# Shuffle\n",
    "indices = np.random.permutation(n_samples)\n",
    "X_2d = X_2d[indices]\n",
    "y_2d = y_2d[indices]\n",
    "\n",
    "# Split\n",
    "X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(\n",
    "    X_2d, y_2d, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "model = LogisticRegression(learning_rate=0.1, n_iterations=1000, random_state=42)\n",
    "model.fit(X_train_2d, y_train_2d)\n",
    "\n",
    "# Evaluate\n",
    "train_acc = model.score(X_train_2d, y_train_2d)\n",
    "test_acc = model.score(X_test_2d, y_test_2d)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc:.4f}\")\n",
    "\n",
    "# Plot decision boundary\n",
    "def plot_decision_boundary(model, X, y, title='Decision Boundary'):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                         np.linspace(y_min, y_max, 200))\n",
    "    \n",
    "    Z = model.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.contourf(xx, yy, Z, levels=20, cmap='RdYlBu', alpha=0.6)\n",
    "    plt.colorbar(label='Probability of class 1')\n",
    "    plt.contour(xx, yy, Z, levels=[0.5], colors='black', linewidths=2)\n",
    "    \n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1], c='blue', label='Class 0', edgecolors='k')\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], c='red', label='Class 1', edgecolors='k')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_decision_boundary(model, X_test_2d, y_test_2d, 'Logistic Regression Decision Boundary')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(model.cost_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "assert test_acc > 0.9, \"Should achieve high accuracy on linearly separable data\"\n",
    "print(\"\\n✓ Logistic regression works on 2D data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Classification Metrics\n",
    "\n",
    "### Background\n",
    "\n",
    "**Confusion Matrix:**\n",
    "```\n",
    "                Predicted\n",
    "              |  0  |  1  |\n",
    "        ------|-----|-----|\n",
    "Actual   0    | TN  | FP  |\n",
    "         1    | FN  | TP  |\n",
    "```\n",
    "\n",
    "**Metrics:**\n",
    "- **Accuracy**: (TP + TN) / Total\n",
    "- **Precision**: TP / (TP + FP) - \"Of predicted positives, how many are correct?\"\n",
    "- **Recall**: TP / (TP + FN) - \"Of actual positives, how many did we find?\"\n",
    "- **F1 Score**: 2 × (Precision × Recall) / (Precision + Recall)\n",
    "\n",
    "### Exercise 4.1: Implement Classification Metrics\n",
    "\n",
    "**Task:** Implement metrics from scratch and compare with sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute confusion matrix.\n",
    "    \n",
    "    Returns: [[TN, FP], [FN, TP]]\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    tn = \n",
    "    fp = \n",
    "    fn = \n",
    "    tp = \n",
    "    \n",
    "    return np.array([[tn, fp], [fn, tp]])\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    \"\"\"Compute accuracy.\"\"\"\n",
    "    # Your code here\n",
    "    return \n",
    "\n",
    "def compute_precision(y_true, y_pred):\n",
    "    \"\"\"Compute precision.\"\"\"\n",
    "    # Your code here\n",
    "    cm = compute_confusion_matrix(y_true, y_pred)\n",
    "    tp = cm[1, 1]\n",
    "    fp = cm[0, 1]\n",
    "    return \n",
    "\n",
    "def compute_recall(y_true, y_pred):\n",
    "    \"\"\"Compute recall (sensitivity).\"\"\"\n",
    "    # Your code here\n",
    "    cm = compute_confusion_matrix(y_true, y_pred)\n",
    "    tp = cm[1, 1]\n",
    "    fn = cm[1, 0]\n",
    "    return \n",
    "\n",
    "def compute_f1_score(y_true, y_pred):\n",
    "    \"\"\"Compute F1 score.\"\"\"\n",
    "    # Your code here\n",
    "    precision = compute_precision(y_true, y_pred)\n",
    "    recall = compute_recall(y_true, y_pred)\n",
    "    return \n",
    "\n",
    "# Test metrics\n",
    "y_pred_test = model.predict(X_test_2d)\n",
    "\n",
    "cm = compute_confusion_matrix(y_test_2d, y_pred_test)\n",
    "acc = compute_accuracy(y_test_2d, y_pred_test)\n",
    "prec = compute_precision(y_test_2d, y_pred_test)\n",
    "rec = compute_recall(y_test_2d, y_pred_test)\n",
    "f1 = compute_f1_score(y_test_2d, y_pred_test)\n",
    "\n",
    "print(\"Your Metrics:\")\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "print(\"\\nSklearn Metrics:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test_2d, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test_2d, y_pred_test):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test_2d, y_pred_test):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test_2d, y_pred_test):.4f}\")\n",
    "\n",
    "assert np.isclose(acc, accuracy_score(y_test_2d, y_pred_test)), \"Accuracy should match\"\n",
    "assert np.isclose(prec, precision_score(y_test_2d, y_pred_test)), \"Precision should match\"\n",
    "assert np.isclose(rec, recall_score(y_test_2d, y_pred_test)), \"Recall should match\"\n",
    "assert np.isclose(f1, f1_score(y_test_2d, y_pred_test)), \"F1 should match\"\n",
    "print(\"\\n✓ All metrics implemented correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2: Visualize Confusion Matrix\n",
    "\n",
    "**Task:** Create a heatmap visualization of the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion Matrix'):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix as heatmap.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(cm, cmap='Blues')\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    \n",
    "    # Set ticks and labels\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_xticklabels(['Predicted 0', 'Predicted 1'])\n",
    "    ax.set_yticklabels(['Actual 0', 'Actual 1'])\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            text = ax.text(j, i, cm[i, j],\n",
    "                          ha=\"center\", va=\"center\", color=\"red\", fontsize=20)\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(cm, 'Confusion Matrix - Test Set')\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(f\"True Negatives (TN):  {cm[0, 0]} - Correctly predicted class 0\")\n",
    "print(f\"False Positives (FP): {cm[0, 1]} - Wrongly predicted class 1\")\n",
    "print(f\"False Negatives (FN): {cm[1, 0]} - Wrongly predicted class 0\")\n",
    "print(f\"True Positives (TP):  {cm[1, 1]} - Correctly predicted class 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: ROC Curve and AUC\n",
    "\n",
    "### Background\n",
    "\n",
    "**ROC (Receiver Operating Characteristic) Curve:**\n",
    "- Plots True Positive Rate (TPR) vs False Positive Rate (FPR) at various thresholds\n",
    "- TPR = Recall = TP / (TP + FN)\n",
    "- FPR = FP / (FP + TN)\n",
    "\n",
    "**AUC (Area Under the Curve):**\n",
    "- Perfect classifier: AUC = 1.0\n",
    "- Random classifier: AUC = 0.5\n",
    "\n",
    "### Exercise 5.1: Plot ROC Curve\n",
    "\n",
    "**Task:** Create an ROC curve and calculate AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities\n",
    "y_proba = model.predict_proba(X_test_2d)\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test_2d, y_proba)\n",
    "auc = roc_auc_score(y_test_2d, y_proba)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier (AUC = 0.5)')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Score: {auc:.4f}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- AUC = 1.0: Perfect classifier\")\n",
    "print(\"- AUC = 0.5: Random classifier\")\n",
    "print(f\"- AUC = {auc:.3f}: Our model's performance\")\n",
    "\n",
    "assert auc > 0.9, \"Should have high AUC on this data\"\n",
    "print(\"\\n✓ ROC curve and AUC calculated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2: Effect of Decision Threshold\n",
    "\n",
    "**Task:** Explore how changing the decision threshold affects metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different thresholds\n",
    "thresholds_test = [0.3, 0.5, 0.7]\n",
    "\n",
    "print(\"Effect of Decision Threshold:\\n\")\n",
    "for thresh in thresholds_test:\n",
    "    y_pred_thresh = model.predict(X_test_2d, threshold=thresh)\n",
    "    \n",
    "    acc = accuracy_score(y_test_2d, y_pred_thresh)\n",
    "    prec = precision_score(y_test_2d, y_pred_thresh)\n",
    "    rec = recall_score(y_test_2d, y_pred_thresh)\n",
    "    f1 = f1_score(y_test_2d, y_pred_thresh)\n",
    "    \n",
    "    print(f\"Threshold = {thresh}:\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    print()\n",
    "\n",
    "print(\"Observations:\")\n",
    "print(\"- Lower threshold (0.3): Higher recall, lower precision\")\n",
    "print(\"- Higher threshold (0.7): Lower recall, higher precision\")\n",
    "print(\"- Trade-off between precision and recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Breast Cancer Dataset\n",
    "\n",
    "### Exercise 6.1: Apply to Breast Cancer Classification\n",
    "\n",
    "**Task:** Use your logistic regression on a real medical dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X_cancer = cancer.data\n",
    "y_cancer = cancer.target  # 0 = malignant, 1 = benign\n",
    "\n",
    "print(\"Breast Cancer Dataset:\")\n",
    "print(f\"Shape: {X_cancer.shape}\")\n",
    "print(f\"Features: {len(cancer.feature_names)}\")\n",
    "print(f\"Classes: {cancer.target_names}\")\n",
    "print(f\"Class distribution: {np.bincount(y_cancer)}\")\n",
    "print()\n",
    "\n",
    "# Split data\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_cancer, y_cancer, test_size=0.2, random_state=42, stratify=y_cancer\n",
    ")\n",
    "\n",
    "# Scale features (important!)\n",
    "scaler = StandardScaler()\n",
    "X_train_c_scaled = scaler.fit_transform(X_train_c)\n",
    "X_test_c_scaled = scaler.transform(X_test_c)\n",
    "\n",
    "# Your turn: Train your model\n",
    "# Your code here\n",
    "model_cancer = \n",
    "\n",
    "# Evaluate\n",
    "y_pred_c = model_cancer.predict(X_test_c_scaled)\n",
    "y_proba_c = model_cancer.predict_proba(X_test_c_scaled)\n",
    "\n",
    "acc_c = accuracy_score(y_test_c, y_pred_c)\n",
    "prec_c = precision_score(y_test_c, y_pred_c)\n",
    "rec_c = recall_score(y_test_c, y_pred_c)\n",
    "f1_c = f1_score(y_test_c, y_pred_c)\n",
    "auc_c = roc_auc_score(y_test_c, y_proba_c)\n",
    "\n",
    "print(\"\\nYour Model Performance:\")\n",
    "print(f\"Accuracy:  {acc_c:.4f}\")\n",
    "print(f\"Precision: {prec_c:.4f}\")\n",
    "print(f\"Recall:    {rec_c:.4f}\")\n",
    "print(f\"F1 Score:  {f1_c:.4f}\")\n",
    "print(f\"AUC:       {auc_c:.4f}\")\n",
    "\n",
    "# Compare with sklearn\n",
    "sklearn_cancer = SklearnLogisticRegression(max_iter=1000, random_state=42)\n",
    "sklearn_cancer.fit(X_train_c_scaled, y_train_c)\n",
    "sklearn_acc = sklearn_cancer.score(X_test_c_scaled, y_test_c)\n",
    "\n",
    "print(f\"\\nSklearn Accuracy: {sklearn_acc:.4f}\")\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_c = confusion_matrix(y_test_c, y_pred_c)\n",
    "im = axes[0].imshow(cm_c, cmap='Blues')\n",
    "plt.colorbar(im, ax=axes[0])\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_yticks([0, 1])\n",
    "axes[0].set_xticklabels(['Malignant', 'Benign'])\n",
    "axes[0].set_yticklabels(['Malignant', 'Benign'])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[0].text(j, i, cm_c[i, j], ha=\"center\", va=\"center\", \n",
    "                    color=\"red\", fontsize=20)\n",
    "axes[0].set_title('Confusion Matrix')\n",
    "\n",
    "# ROC curve\n",
    "fpr_c, tpr_c, _ = roc_curve(y_test_c, y_proba_c)\n",
    "axes[1].plot(fpr_c, tpr_c, linewidth=2, label=f'AUC = {auc_c:.3f}')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', linewidth=2)\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curve')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss curve\n",
    "axes[2].plot(model_cancer.cost_history)\n",
    "axes[2].set_xlabel('Iteration')\n",
    "axes[2].set_ylabel('Cost')\n",
    "axes[2].set_title('Training Loss')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Successfully applied to breast cancer dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Wine Dataset (Binary Classification)\n",
    "\n",
    "### Exercise 7.1: Binary Classification on Wine Dataset\n",
    "\n",
    "**Task:** Convert multi-class wine dataset to binary and classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wine dataset\n",
    "wine = load_wine()\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target  # 3 classes: 0, 1, 2\n",
    "\n",
    "# Convert to binary: class 0 vs rest (1 or 2)\n",
    "y_wine_binary = (y_wine == 0).astype(int)\n",
    "\n",
    "print(\"Wine Dataset (Binary):\")\n",
    "print(f\"Shape: {X_wine.shape}\")\n",
    "print(f\"Original classes: {wine.target_names}\")\n",
    "print(f\"Binary: Class 0 ({wine.target_names[0]}) vs Rest\")\n",
    "print(f\"Class distribution: {np.bincount(y_wine_binary)}\")\n",
    "print()\n",
    "\n",
    "# Your turn: Complete the pipeline\n",
    "# Split data\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = \n",
    "\n",
    "# Scale features\n",
    "scaler_w = StandardScaler()\n",
    "X_train_w_scaled = \n",
    "X_test_w_scaled = \n",
    "\n",
    "# Train model\n",
    "model_wine = \n",
    "\n",
    "# Evaluate\n",
    "acc_w = \n",
    "auc_w = \n",
    "\n",
    "print(f\"Test Accuracy: {acc_w:.4f}\")\n",
    "print(f\"Test AUC:      {auc_w:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "y_pred_w = model_wine.predict(X_test_w_scaled)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_w, y_pred_w, \n",
    "                          target_names=['Class 1&2', 'Class 0']))\n",
    "\n",
    "print(\"\\n✓ Successfully applied to wine dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Iris Dataset (Binary Classification)\n",
    "\n",
    "### Exercise 8.1: Binary Classification on Iris Dataset\n",
    "\n",
    "**Task:** Use only 2 features from Iris for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Use only 2 features for visualization: petal length and petal width\n",
    "X_iris = iris.data[:, 2:4]  # petal features\n",
    "y_iris = (iris.target == 0).astype(int)  # Setosa vs rest\n",
    "\n",
    "print(\"Iris Dataset (Binary):\")\n",
    "print(f\"Features: Petal length, Petal width\")\n",
    "print(f\"Binary: Setosa vs Versicolor/Virginica\")\n",
    "print(f\"Class distribution: {np.bincount(y_iris)}\")\n",
    "print()\n",
    "\n",
    "# Split and scale\n",
    "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "scaler_i = StandardScaler()\n",
    "X_train_i_scaled = scaler_i.fit_transform(X_train_i)\n",
    "X_test_i_scaled = scaler_i.transform(X_test_i)\n",
    "\n",
    "# Train\n",
    "model_iris = LogisticRegression(learning_rate=0.1, n_iterations=1000, random_state=42)\n",
    "model_iris.fit(X_train_i_scaled, y_train_i)\n",
    "\n",
    "# Evaluate\n",
    "acc_i = model_iris.score(X_test_i_scaled, y_test_i)\n",
    "print(f\"Test Accuracy: {acc_i:.4f}\")\n",
    "\n",
    "# Plot decision boundary (with scaling)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "# Transform back to original scale for plotting\n",
    "x_min, x_max = X_iris[:, 0].min() - 0.5, X_iris[:, 0].max() + 0.5\n",
    "y_min, y_max = X_iris[:, 1].min() - 0.5, X_iris[:, 1].max() + 0.5\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                     np.linspace(y_min, y_max, 200))\n",
    "\n",
    "# Scale the meshgrid\n",
    "Z = model_iris.predict_proba(scaler_i.transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, levels=20, cmap='RdYlBu', alpha=0.6)\n",
    "plt.colorbar(label='P(Setosa)')\n",
    "plt.contour(xx, yy, Z, levels=[0.5], colors='black', linewidths=2)\n",
    "plt.scatter(X_iris[y_iris == 0, 0], X_iris[y_iris == 0, 1], \n",
    "           c='red', label='Setosa', edgecolors='k')\n",
    "plt.scatter(X_iris[y_iris == 1, 0], X_iris[y_iris == 1, 1], \n",
    "           c='blue', label='Other', edgecolors='k')\n",
    "plt.xlabel('Petal Length (cm)')\n",
    "plt.ylabel('Petal Width (cm)')\n",
    "plt.title('Iris Decision Boundary')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(model_iris.cost_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Successfully applied to iris dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challenge Problems (Optional)\n",
    "\n",
    "### Challenge 1: Multi-Class Logistic Regression (Softmax)\n",
    "\n",
    "Extend logistic regression to handle multiple classes using softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Compute softmax function.\n",
    "    \n",
    "    softmax(z_i) = exp(z_i) / sum(exp(z_j))\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    # Hint: Subtract max for numerical stability\n",
    "    pass\n",
    "\n",
    "class MultiClassLogisticRegression:\n",
    "    \"\"\"\n",
    "    Multi-class logistic regression using softmax.\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Your code here\n",
    "        pass\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Your code here\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Your code here\n",
    "        pass\n",
    "\n",
    "print(\"Challenge 1: Implement multi-class logistic regression!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: L2 Regularization\n",
    "\n",
    "Add L2 regularization to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularizedLogisticRegression(LogisticRegression):\n",
    "    \"\"\"\n",
    "    Logistic regression with L2 regularization.\n",
    "    \n",
    "    Cost = BCE + (lambda / 2m) * sum(w^2)\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000, \n",
    "                 lambda_reg=0.1, random_state=None):\n",
    "        super().__init__(learning_rate, n_iterations, random_state)\n",
    "        self.lambda_reg = lambda_reg\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Your code here\n",
    "        # Modify gradient to include regularization term\n",
    "        pass\n",
    "\n",
    "print(\"Challenge 2: Implement L2 regularization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Custom Loss Function\n",
    "\n",
    "Implement focal loss for imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(y_true, y_pred, gamma=2.0):\n",
    "    \"\"\"\n",
    "    Focal loss for imbalanced datasets.\n",
    "    \n",
    "    FL = -alpha * (1-p)^gamma * log(p)\n",
    "    \n",
    "    Focuses training on hard examples.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "print(\"Challenge 3: Implement focal loss!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reflection Questions\n",
    "\n",
    "1. **Why use sigmoid instead of a linear function for classification?**\n",
    "   - What do we want the output to represent?\n",
    "\n",
    "2. **Why use cross-entropy instead of MSE for classification?**\n",
    "   - Think about the gradient behavior\n",
    "\n",
    "3. **When is accuracy not a good metric?**\n",
    "   - Consider imbalanced datasets\n",
    "\n",
    "4. **Precision vs Recall: Which is more important?**\n",
    "   - Depends on the application (medical diagnosis, spam detection, etc.)\n",
    "\n",
    "5. **What does AUC = 0.5 mean?**\n",
    "   - Is the model learning anything?\n",
    "\n",
    "6. **How do you choose the decision threshold?**\n",
    "   - Consider the cost of false positives vs false negatives\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this exercise, you learned:\n",
    "\n",
    "✓ How to implement logistic regression from scratch  \n",
    "✓ The sigmoid function and its properties  \n",
    "✓ Binary cross-entropy loss for classification  \n",
    "✓ Classification metrics: accuracy, precision, recall, F1  \n",
    "✓ ROC curves and AUC for model evaluation  \n",
    "✓ Decision boundary visualization  \n",
    "✓ Application to real medical and wine datasets  \n",
    "✓ Effect of decision threshold on metrics  \n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "- **Sigmoid**: Maps to (0, 1) for probability interpretation\n",
    "- **Cross-entropy**: Appropriate loss for classification\n",
    "- **Metrics matter**: Choose based on application\n",
    "- **Threshold tuning**: Balance precision and recall\n",
    "- **Feature scaling**: Essential for gradient descent\n",
    "- **AUC**: Threshold-independent performance measure\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "- Complete Exercise 4 on Regularization\n",
    "- Review the [Logistic Regression lesson](https://jumpingsphinx.github.io/module2-regression/03-logistic-regression/)\n",
    "- Experiment with multi-class classification\n",
    "- Try handling imbalanced datasets\n",
    "\n",
    "---\n",
    "\n",
    "**Need help?** Check the solution notebook or open an issue on [GitHub](https://github.com/jumpingsphinx/jumpingsphinx.github.io/issues)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}