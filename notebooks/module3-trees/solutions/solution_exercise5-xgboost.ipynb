{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - Exercise 5: XGBoost\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jumpingsphinx/jumpingsphinx.github.io/blob/main/notebooks/module3-trees/exercise5-xgboost.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this exercise, you will be able to:\n",
    "\n",
    "- Apply XGBoost for classification and regression\n",
    "- Perform systematic hyperparameter tuning\n",
    "- Implement early stopping and cross-validation\n",
    "- Analyze feature importance (gain, weight, cover)\n",
    "- Handle imbalanced data with scale_pos_weight\n",
    "- Compare XGBoost with other algorithms\n",
    "- Build complete ML pipelines\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completion of Exercise 4 (Boosting)\n",
    "- Understanding of gradient boosting\n",
    "- Familiarity with hyperparameter tuning\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run this cell first to import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install XGBoost (required for Google Colab)\n",
    "!pip install xgboost -q\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer, load_wine, fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, roc_curve, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(\"\\nSetup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: XGBoost Basics\n",
    "\n",
    "### Background\n",
    "\n",
    "**XGBoost** (eXtreme Gradient Boosting) is an optimized gradient boosting library that has become the dominant algorithm for structured/tabular data in machine learning competitions.\n",
    "\n",
    "**Key advantages:**\n",
    "- Speed: Highly optimized C++ backend\n",
    "- Performance: Often achieves state-of-the-art results\n",
    "- Regularization: Built-in L1 and L2 regularization\n",
    "- Missing values: Handles them automatically\n",
    "- Parallel processing: Tree construction is parallelized\n",
    "- Built-in cross-validation\n",
    "\n",
    "**Core hyperparameters:**\n",
    "- `n_estimators`: Number of boosting rounds (trees)\n",
    "- `max_depth`: Maximum tree depth\n",
    "- `learning_rate` (eta): Step size shrinkage (0.01-0.3)\n",
    "- `subsample`: Fraction of samples for each tree (0.5-1.0)\n",
    "- `colsample_bytree`: Fraction of features for each tree (0.5-1.0)\n",
    "- `gamma`: Minimum loss reduction for split\n",
    "- `reg_alpha`: L1 regularization\n",
    "- `reg_lambda`: L2 regularization\n",
    "\n",
    "### Exercise 1.1: Simple Classification with XGBoost\n",
    "\n",
    "**Task:** Train XGBoost on the Breast Cancer dataset with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Breast Cancer dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "cancer = load_breast_cancer()\n",
    "X_cancer = cancer.data\n",
    "y_cancer = cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, test_size=0.2, random_state=42, stratify=y_cancer)\n",
    "\n",
    "# Create and train XGBoost classifier\n",
    "xgb_basic = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "xgb_basic.fit(X_train, y_train)\n",
    "y_pred_train = xgb_basic.predict(X_train)\n",
    "y_pred_test = xgb_basic.predict(X_test)\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Early Stopping\n",
    "\n",
    "### Background\n",
    "\n",
    "**Early stopping** monitors performance on a validation set and stops training when performance stops improving. This prevents overfitting and saves computation time.\n",
    "\n",
    "**Key parameter:**\n",
    "- `early_stopping_rounds`: Stop if no improvement for N rounds\n",
    "\n",
    "**Usage:**\n",
    "```python\n",
    "model.fit(X_train, y_train,\n",
    "          eval_set=[(X_val, y_val)],\n",
    "          early_stopping_rounds=10)\n",
    "```\n",
    "\n",
    "### Exercise 2.1: Implement Early Stopping\n",
    "\n",
    "**Task:** Use early stopping to find the optimal number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/validation/test split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_cancer, y_cancer, test_size=0.2, random_state=42, stratify=y_cancer\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print()\n",
    "\n",
    "# Your code here: Train XGBoost with early stopping\n",
    "xgb_early = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "\n",
    "xgb_early.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "print(f\"\\nBest iteration: {xgb_early.best_iteration}\")\n",
    "print(f\"Best score: {xgb_early.best_score:.4f}\")\n",
    "print()\n",
    "\n",
    "# Retrieve evaluation results\n",
    "results = xgb_early.evals_result()\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(results['validation_0']['logloss'], label='Training')\n",
    "plt.plot(results['validation_1']['logloss'], label='Validation')\n",
    "plt.axvline(x=xgb_early.best_iteration, color='r', linestyle='--', \n",
    "           label=f'Best iteration ({xgb_early.best_iteration})')\n",
    "plt.xlabel('Boosting Round')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Calculate accuracy from predictions\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for i in range(len(results['validation_0']['logloss'])):\n",
    "    xgb_temp = XGBClassifier(\n",
    "        n_estimators=i+1,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    xgb_temp.fit(X_train, y_train, verbose=False)\n",
    "    if i % 20 == 0 or i < 10:  # Sample points to speed up\n",
    "        train_accs.append((i, accuracy_score(y_train, xgb_temp.predict(X_train))))\n",
    "        val_accs.append((i, accuracy_score(y_val, xgb_temp.predict(X_val))))\n",
    "\n",
    "train_iters, train_acc_vals = zip(*train_accs) if train_accs else ([], [])\n",
    "val_iters, val_acc_vals = zip(*val_accs) if val_accs else ([], [])\n",
    "\n",
    "plt.plot(train_iters, train_acc_vals, 'o-', label='Training', alpha=0.7)\n",
    "plt.plot(val_iters, val_acc_vals, 's-', label='Validation', alpha=0.7)\n",
    "plt.axvline(x=xgb_early.best_iteration, color='r', linestyle='--',\n",
    "           label=f'Best iteration ({xgb_early.best_iteration})')\n",
    "plt.xlabel('Boosting Round')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_acc = accuracy_score(y_test, xgb_early.predict(X_test))\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"\\n✓ Early stopping prevents overfitting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Hyperparameter Tuning\n",
    "\n",
    "### Background\n",
    "\n",
    "Systematic hyperparameter tuning is crucial for XGBoost performance.\n",
    "\n",
    "**Tuning strategy:**\n",
    "1. Fix learning_rate at 0.1\n",
    "2. Tune tree-specific parameters (max_depth, min_child_weight)\n",
    "3. Tune sampling parameters (subsample, colsample_bytree)\n",
    "4. Tune regularization (gamma, reg_alpha, reg_lambda)\n",
    "5. Lower learning_rate and increase n_estimators\n",
    "\n",
    "### Exercise 3.1: Grid Search for Hyperparameters\n",
    "\n",
    "**Task:** Perform systematic grid search on key XGBoost parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter Grid:\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "print(f\"\\nTotal combinations: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "print(\"\\nThis will take a few minutes...\\n\")\n",
    "\n",
    "# Your code here: Perform grid search\n",
    "xgb_grid = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    xgb_grid,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_full, y_train_full)\n",
    "print(\"\\nBest parameters:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nBest CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate best model on test set\n",
    "best_xgb = grid_search.best_estimator_\n",
    "test_acc = accuracy_score(y_test, best_xgb.predict(X_test))\n",
    "test_auc = roc_auc_score(y_test, best_xgb.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test AUC-ROC: {test_auc:.4f}\")\n",
    "\n",
    "# Visualize top parameter combinations\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "results_df = results_df.sort_values('rank_test_score')\n",
    "\n",
    "print(\"\\nTop 5 parameter combinations:\")\n",
    "print(results_df[['params', 'mean_test_score', 'std_test_score']].head())\n",
    "\n",
    "print(\"\\n✓ Hyperparameter tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Feature Importance Types\n",
    "\n",
    "### Background\n",
    "\n",
    "XGBoost provides three types of feature importance:\n",
    "\n",
    "1. **Weight (Frequency)**: Number of times feature appears in splits\n",
    "2. **Gain**: Average improvement in loss when splitting on feature\n",
    "3. **Cover**: Average number of samples affected by splits on feature\n",
    "\n",
    "**Best practice:** Use 'gain' for most interpretable results.\n",
    "\n",
    "### Exercise 4.1: Compare Feature Importance Metrics\n",
    "\n",
    "**Task:** Analyze feature importance using all three metrics on Wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Wine dataset\n",
    "wine = load_wine()\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "\n",
    "print(\"Wine Dataset:\")\n",
    "print(f\"Shape: {X_wine.shape}\")\n",
    "print(f\"Classes: {wine.target_names}\")\n",
    "print(f\"Features: {wine.feature_names}\")\n",
    "print()\n",
    "\n",
    "# Split data\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(\n",
    "    X_wine, y_wine, test_size=0.2, random_state=42, stratify=y_wine\n",
    ")\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_wine = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss'  # For multiclass\n",
    ")\n",
    "\n",
    "xgb_wine.fit(X_train_wine, y_train_wine)\n",
    "\n",
    "# Get feature importance with different metrics\n",
    "importance_types = ['weight', 'gain', 'cover']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, importance_type in enumerate(importance_types):\n",
    "    # Get importance\n",
    "    importance = xgb_wine.get_booster().get_score(importance_type=importance_type)\n",
    "    \n",
    "    # Convert to feature names and sort\n",
    "    feature_importance = {}\n",
    "    for key, value in importance.items():\n",
    "        feature_idx = int(key[1:])  # Remove 'f' prefix\n",
    "        feature_importance[wine.feature_names[feature_idx]] = value\n",
    "    \n",
    "    # Sort by importance\n",
    "    sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "    features, importances = zip(*sorted_features)\n",
    "    \n",
    "    # Plot\n",
    "    axes[idx].barh(range(len(features)), importances, alpha=0.7)\n",
    "    axes[idx].set_yticks(range(len(features)))\n",
    "    axes[idx].set_yticklabels(features)\n",
    "    axes[idx].set_xlabel(f'{importance_type.capitalize()} Importance')\n",
    "    axes[idx].set_title(f'Feature Importance: {importance_type.upper()}')\n",
    "    axes[idx].invert_yaxis()\n",
    "    axes[idx].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print top features for each metric\n",
    "print(\"Top 5 features by importance type:\\n\")\n",
    "for importance_type in importance_types:\n",
    "    importance = xgb_wine.get_booster().get_score(importance_type=importance_type)\n",
    "    feature_importance = {}\n",
    "    for key, value in importance.items():\n",
    "        feature_idx = int(key[1:])\n",
    "        feature_importance[wine.feature_names[feature_idx]] = value\n",
    "    \n",
    "    sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    \n",
    "    print(f\"{importance_type.upper()}:\")\n",
    "    for i, (feature, score) in enumerate(sorted_features, 1):\n",
    "        print(f\"  {i}. {feature}: {score:.2f}\")\n",
    "    print()\n",
    "\n",
    "# Evaluate model\n",
    "test_acc = accuracy_score(y_test_wine, xgb_wine.predict(X_test_wine))\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"\\n✓ Feature importance analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: XGBoost Regression\n",
    "\n",
    "### Background\n",
    "\n",
    "XGBoost excels at regression tasks as well as classification.\n",
    "\n",
    "**Key differences for regression:**\n",
    "- Use `XGBRegressor` instead of `XGBClassifier`\n",
    "- Evaluation metrics: RMSE, MAE, R²\n",
    "- Objective function: `reg:squarederror` (default)\n",
    "\n",
    "### Exercise 5.1: XGBoost for California Housing\n",
    "\n",
    "**Task:** Apply XGBoost regression with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Housing Data\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "housing = fetch_california_housing()\n",
    "X_h, y_h = housing.data, housing.target\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(X_h, y_h, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_h_scaled = scaler.fit_transform(X_train_h)\n",
    "X_test_h_scaled = scaler.transform(X_test_h)\n",
    "\n",
    "# Train Baseline\n",
    "xgb_reg_baseline = XGBRegressor(random_state=42)\n",
    "xgb_reg_baseline.fit(X_train_h_scaled, y_train_h)\n",
    "\n",
    "# Predict\n",
    "y_pred_train = xgb_reg_baseline.predict(X_train_h_scaled)\n",
    "y_pred_test = xgb_reg_baseline.predict(X_test_h_scaled)\n",
    "\n",
    "# Evaluate\n",
    "train_mse = mean_squared_error(y_train_h, y_pred_train)\n",
    "test_mse = mean_squared_error(y_test_h, y_pred_test)\n",
    "test_r2 = r2_score(y_test_h, y_pred_test)\n",
    "\n",
    "print(\"Baseline XGBoost Regression:\")\n",
    "print(f\"Train MSE: {train_mse:.4f}\")\n",
    "print(f\"Test MSE:  {test_mse:.4f}\")\n",
    "print(f\"Test R²:   {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Imbalanced Classification\n",
    "\n",
    "### Background\n",
    "\n",
    "Real-world datasets are often imbalanced (e.g., fraud detection, disease diagnosis).\n",
    "\n",
    "**XGBoost solutions:**\n",
    "1. `scale_pos_weight`: Weight for positive class = (count_negative / count_positive)\n",
    "2. Custom evaluation metrics (AUC-ROC, F1, Precision-Recall)\n",
    "3. Threshold adjustment\n",
    "\n",
    "### Exercise 6.1: Handle Imbalanced Data\n",
    "\n",
    "**Task:** Create imbalanced dataset and use scale_pos_weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create imbalanced dataset from Breast Cancer\n",
    "# Keep all malignant (class 0) and only 10% of benign (class 1)\n",
    "np.random.seed(42)\n",
    "\n",
    "malignant_idx = np.where(y_cancer == 0)[0]\n",
    "benign_idx = np.where(y_cancer == 1)[0]\n",
    "\n",
    "# Keep all malignant and subsample benign to create 1:9 imbalance\n",
    "n_benign_keep = len(malignant_idx) // 9\n",
    "benign_idx_sample = np.random.choice(benign_idx, size=n_benign_keep, replace=False)\n",
    "\n",
    "# Combine indices\n",
    "imbalanced_idx = np.concatenate([malignant_idx, benign_idx_sample])\n",
    "np.random.shuffle(imbalanced_idx)\n",
    "\n",
    "X_imbalanced = X_cancer[imbalanced_idx]\n",
    "y_imbalanced = y_cancer[imbalanced_idx]\n",
    "\n",
    "print(\"Imbalanced Dataset:\")\n",
    "print(f\"Total samples: {len(y_imbalanced)}\")\n",
    "print(f\"Class 0 (malignant): {np.sum(y_imbalanced == 0)} ({np.sum(y_imbalanced == 0) / len(y_imbalanced) * 100:.1f}%)\")\n",
    "print(f\"Class 1 (benign): {np.sum(y_imbalanced == 1)} ({np.sum(y_imbalanced == 1) / len(y_imbalanced) * 100:.1f}%)\")\n",
    "print(f\"Imbalance ratio: 1:{len(malignant_idx) / n_benign_keep:.1f}\")\n",
    "print()\n",
    "\n",
    "# Split data\n",
    "X_train_imb, X_test_imb, y_train_imb, y_test_imb = train_test_split(\n",
    "    X_imbalanced, y_imbalanced, test_size=0.2, random_state=42, stratify=y_imbalanced\n",
    ")\n",
    "\n",
    "# Train without scale_pos_weight\n",
    "xgb_no_weight = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_no_weight.fit(X_train_imb, y_train_imb)\n",
    "y_pred_no_weight = xgb_no_weight.predict(X_test_imb)\n",
    "\n",
    "# Your code here: Calculate scale_pos_weight and train with it\n",
    "scale_pos_weight = np.sum(y_train_imb == 0) / np.sum(y_train_imb == 1)\n",
    "\n",
    "xgb_with_weight = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_with_weight.fit(X_train_imb, y_train_imb)\n",
    "print(f\"Calculated scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "print()\n",
    "\n",
    "xgb_with_weight = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_with_weight.fit(X_train_imb, y_train_imb)\n",
    "y_pred_with_weight = xgb_with_weight.predict(X_test_imb)\n",
    "\n",
    "# Compare results\n",
    "print(\"Performance Comparison:\\n\")\n",
    "\n",
    "print(\"WITHOUT scale_pos_weight:\")\n",
    "print(classification_report(y_test_imb, y_pred_no_weight, \n",
    "                          target_names=['Malignant', 'Benign']))\n",
    "\n",
    "print(\"\\nWITH scale_pos_weight:\")\n",
    "print(classification_report(y_test_imb, y_pred_with_weight,\n",
    "                          target_names=['Malignant', 'Benign']))\n",
    "\n",
    "# ROC curves\n",
    "y_proba_no_weight = xgb_no_weight.predict_proba(X_test_imb)[:, 1]\n",
    "y_proba_with_weight = xgb_with_weight.predict_proba(X_test_imb)[:, 1]\n",
    "\n",
    "fpr_no, tpr_no, _ = roc_curve(y_test_imb, y_proba_no_weight)\n",
    "fpr_with, tpr_with, _ = roc_curve(y_test_imb, y_proba_with_weight)\n",
    "\n",
    "auc_no = roc_auc_score(y_test_imb, y_proba_no_weight)\n",
    "auc_with = roc_auc_score(y_test_imb, y_proba_with_weight)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_no, tpr_no, label=f'Without weight (AUC = {auc_no:.3f})', linewidth=2)\n",
    "plt.plot(fpr_with, tpr_with, label=f'With weight (AUC = {auc_with:.3f})', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves: Impact of scale_pos_weight')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Imbalanced classification handled!\")\n",
    "print(\"\\nKey observation: scale_pos_weight improves recall on minority class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Comparing XGBoost vs Random Forest vs Gradient Boosting\n",
    "\n",
    "### Background\n",
    "\n",
    "**Head-to-head comparison** of three ensemble methods:\n",
    "\n",
    "| Method | Speed | Accuracy | Overfitting | Tuning |\n",
    "|--------|-------|----------|-------------|--------|\n",
    "| Random Forest | Fast | Good | Low | Easy |\n",
    "| Gradient Boosting | Medium | Very Good | Medium | Moderate |\n",
    "| XGBoost | Very Fast | Excellent | Low (regularized) | Complex |\n",
    "\n",
    "### Exercise 7.1: Comprehensive Comparison\n",
    "\n",
    "**Task:** Compare all three methods on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Breast Cancer dataset\n",
    "X_train_comp, X_test_comp, y_train_comp, y_test_comp = train_test_split(\n",
    "    X_cancer, y_cancer, test_size=0.2, random_state=42, stratify=y_cancer\n",
    ")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "import time\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"Training and evaluating models...\\n\")\n",
    "print(f\"{'Model':<20} {'Train Time (s)':<15} {'Train Acc':<12} {'Test Acc':<12} {'AUC-ROC'}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_comp, y_train_comp)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train_comp)\n",
    "    y_pred_test = model.predict(X_test_comp)\n",
    "    y_proba_test = model.predict_proba(X_test_comp)[:, 1]\n",
    "    \n",
    "    # Metrics\n",
    "    train_acc = accuracy_score(y_train_comp, y_pred_train)\n",
    "    test_acc = accuracy_score(y_test_comp, y_pred_test)\n",
    "    auc = roc_auc_score(y_test_comp, y_proba_test)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'train_time': train_time,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'auc': auc,\n",
    "        'y_proba': y_proba_test\n",
    "    }\n",
    "    \n",
    "    print(f\"{name:<20} {train_time:<15.4f} {train_acc:<12.4f} {test_acc:<12.4f} {auc:.4f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Visualize ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for name, result in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test_comp, result['y_proba'])\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=f\"{name} (AUC = {result['auc']:.3f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves: XGBoost vs Random Forest vs Gradient Boosting')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Cross-validation comparison\n",
    "print(\"\\nCross-Validation Comparison (5-fold):\\n\")\n",
    "print(f\"{'Model':<20} {'Mean CV Score':<15} {'Std CV Score'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_cancer, y_cancer, cv=5, scoring='accuracy')\n",
    "    print(f\"{name:<20} {cv_scores.mean():<15.4f} {cv_scores.std():.4f}\")\n",
    "\n",
    "print(\"\\n✓ Comparison complete!\")\n",
    "print(\"\\nKey insights:\")\n",
    "print(\"- XGBoost typically fastest training time\")\n",
    "print(\"- Similar accuracy across methods (well-tuned data)\")\n",
    "print(\"- XGBoost has regularization built-in (less overfitting)\")\n",
    "print(\"- Random Forest easiest to tune\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Model Persistence\n",
    "\n",
    "### Background\n",
    "\n",
    "Trained models need to be saved for production deployment.\n",
    "\n",
    "**XGBoost options:**\n",
    "1. **Pickle/Joblib**: Python-specific, includes sklearn wrapper\n",
    "2. **save_model/load_model**: XGBoost native binary format (preferred)\n",
    "3. **JSON**: Human-readable, cross-platform\n",
    "\n",
    "### Exercise 8.1: Save and Load XGBoost Models\n",
    "\n",
    "**Task:** Save a trained model and reload it for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Train a model to save\n",
    "xgb_to_save = XGBClassifier(\n",
    "    n_estimators=50,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_to_save.fit(X_train, y_train)\n",
    "original_predictions = xgb_to_save.predict(X_test)\n",
    "original_accuracy = accuracy_score(y_test, original_predictions)\n",
    "\n",
    "print(f\"Original model accuracy: {original_accuracy:.4f}\\n\")\n",
    "\n",
    "# Method 1: Pickle (Python-specific)\n",
    "print(\"Method 1: Pickle\")\n",
    "pickle_file = 'xgb_model.pkl'\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(xgb_to_save, f)\n",
    "print(f\"  Saved to {pickle_file}\")\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    xgb_loaded_pickle = pickle.load(f)\n",
    "pickle_predictions = xgb_loaded_pickle.predict(X_test)\n",
    "pickle_accuracy = accuracy_score(y_test, pickle_predictions)\n",
    "print(f\"  Loaded accuracy: {pickle_accuracy:.4f}\")\n",
    "print(f\"  Predictions match: {np.array_equal(original_predictions, pickle_predictions)}\\n\")\n",
    "\n",
    "# Method 2: XGBoost native format (recommended)\n",
    "print(\"Method 2: XGBoost native binary\")\n",
    "binary_file = 'xgb_model.ubj'\n",
    "xgb_to_save.save_model(binary_file)\n",
    "print(f\"  Saved to {binary_file}\")\n",
    "\n",
    "xgb_loaded_binary = XGBClassifier()\n",
    "xgb_loaded_binary.load_model(binary_file)\n",
    "binary_predictions = xgb_loaded_binary.predict(X_test)\n",
    "binary_accuracy = accuracy_score(y_test, binary_predictions)\n",
    "print(f\"  Loaded accuracy: {binary_accuracy:.4f}\")\n",
    "print(f\"  Predictions match: {np.array_equal(original_predictions, binary_predictions)}\\n\")\n",
    "\n",
    "# Method 3: JSON (human-readable)\n",
    "print(\"Method 3: JSON (human-readable)\")\n",
    "json_file = 'xgb_model.json'\n",
    "xgb_to_save.save_model(json_file)\n",
    "print(f\"  Saved to {json_file}\")\n",
    "\n",
    "xgb_loaded_json = XGBClassifier()\n",
    "xgb_loaded_json.load_model(json_file)\n",
    "json_predictions = xgb_loaded_json.predict(X_test)\n",
    "json_accuracy = accuracy_score(y_test, json_predictions)\n",
    "print(f\"  Loaded accuracy: {json_accuracy:.4f}\")\n",
    "print(f\"  Predictions match: {np.array_equal(original_predictions, json_predictions)}\\n\")\n",
    "\n",
    "# Compare file sizes\n",
    "print(\"File sizes:\")\n",
    "for filename in [pickle_file, binary_file, json_file]:\n",
    "    size_kb = os.path.getsize(filename) / 1024\n",
    "    print(f\"  {filename}: {size_kb:.2f} KB\")\n",
    "\n",
    "# Clean up\n",
    "for filename in [pickle_file, binary_file, json_file]:\n",
    "    os.remove(filename)\n",
    "\n",
    "print(\"\\n✓ Model persistence complete!\")\n",
    "print(\"\\nRecommendation: Use save_model/load_model with .ubj or .json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Complete ML Pipeline\n",
    "\n",
    "### Background\n",
    "\n",
    "A production ML pipeline includes:\n",
    "1. Data preprocessing\n",
    "2. Feature engineering\n",
    "3. Train/validation/test split\n",
    "4. Hyperparameter tuning\n",
    "5. Model training\n",
    "6. Evaluation\n",
    "7. Model persistence\n",
    "\n",
    "### Exercise 9.1: End-to-End Pipeline\n",
    "\n",
    "**Task:** Build a complete pipeline for Wine classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "print(\"Building complete ML pipeline for Wine classification\\n\")\n",
    "\n",
    "# Step 1: Split data (train/val/test)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "print()\n",
    "\n",
    "# Step 2: Create preprocessing pipeline\n",
    "preprocessor = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Fit preprocessor on training data only\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Step 3: Hyperparameter tuning with early stopping\n",
    "print(\"Step 1: Hyperparameter tuning...\\n\")\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.1, 0.3],\n",
    "    'n_estimators': [50, 100]\n",
    "}\n",
    "\n",
    "xgb_pipeline = XGBClassifier(\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    xgb_pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print()\n",
    "\n",
    "# Step 4: Train final model with early stopping\n",
    "print(\"Step 2: Training final model with early stopping...\\n\")\n",
    "\n",
    "final_model = XGBClassifier(\n",
    "    **grid_search.best_params_,\n",
    "    n_estimators=200,  # Allow more trees\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "final_model.fit(\n",
    "    X_train_processed, y_train,\n",
    "    eval_set=[(X_train_processed, y_train), (X_val_processed, y_val)],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"Optimal number of trees: {final_model.best_iteration}\")\n",
    "print()\n",
    "\n",
    "# Step 5: Comprehensive evaluation\n",
    "print(\"Step 3: Model evaluation\\n\")\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = final_model.predict(X_train_processed)\n",
    "y_pred_val = final_model.predict(X_val_processed)\n",
    "y_pred_test = final_model.predict(X_test_processed)\n",
    "\n",
    "# Metrics\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "val_acc = accuracy_score(y_val, y_pred_val)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Test Set Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=wine.target_names))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=wine.target_names,\n",
    "           yticklabels=wine.target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Final Model')\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Feature importance\n",
    "importance = final_model.get_booster().get_score(importance_type='gain')\n",
    "feature_importance = {}\n",
    "for key, value in importance.items():\n",
    "    feature_idx = int(key[1:])\n",
    "    feature_importance[wine.feature_names[feature_idx]] = value\n",
    "\n",
    "sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "features, importances = zip(*sorted_features[:10])\n",
    "plt.barh(range(len(features)), importances, alpha=0.7)\n",
    "plt.yticks(range(len(features)), features)\n",
    "plt.xlabel('Importance (Gain)')\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 7: Save complete pipeline\n",
    "print(\"\\nStep 4: Saving pipeline...\\n\")\n",
    "\n",
    "pipeline_dict = {\n",
    "    'preprocessor': preprocessor,\n",
    "    'model': final_model,\n",
    "    'feature_names': wine.feature_names,\n",
    "    'target_names': wine.target_names.tolist()\n",
    "}\n",
    "\n",
    "with open('wine_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline_dict, f)\n",
    "\n",
    "print(\"Pipeline saved to wine_pipeline.pkl\")\n",
    "\n",
    "# Test loading and prediction\n",
    "with open('wine_pipeline.pkl', 'rb') as f:\n",
    "    loaded_pipeline = pickle.load(f)\n",
    "\n",
    "# Make prediction on new sample\n",
    "sample = X_test[0:1]\n",
    "sample_processed = loaded_pipeline['preprocessor'].transform(sample)\n",
    "prediction = loaded_pipeline['model'].predict(sample_processed)\n",
    "prediction_proba = loaded_pipeline['model'].predict_proba(sample_processed)\n",
    "\n",
    "print(f\"\\nSample prediction: {loaded_pipeline['target_names'][prediction[0]]}\")\n",
    "print(f\"Confidence: {prediction_proba[0][prediction[0]]:.4f}\")\n",
    "\n",
    "# Clean up\n",
    "os.remove('wine_pipeline.pkl')\n",
    "\n",
    "print(\"\\n✓ Complete ML pipeline built successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 10: Kaggle-Style Challenge\n",
    "\n",
    "### Background\n",
    "\n",
    "In Kaggle competitions, you need to:\n",
    "1. Maximize a specific metric (accuracy, AUC, RMSE, etc.)\n",
    "2. Create predictions for a test set\n",
    "3. Submit in required format\n",
    "\n",
    "### Exercise 10.1: Mini Competition\n",
    "\n",
    "**Task:** Build the best XGBoost model for California Housing (minimize RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "print(\"KAGGLE-STYLE CHALLENGE: California Housing Price Prediction\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nObjective: Minimize RMSE on test set\")\n",
    "print(\"\\nDataset:\")\n",
    "print(f\"  Samples: {X.shape[0]}\")\n",
    "print(f\"  Features: {X.shape[1]}\")\n",
    "print(f\"  Target: Median house value ($100k)\")\n",
    "print()\n",
    "\n",
    "# Create train/test split (simulate Kaggle setup)\n",
    "X_train_kaggle, X_test_kaggle, y_train_kaggle, y_test_kaggle = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train_kaggle.shape}\")\n",
    "print(f\"Test set: {X_test_kaggle.shape} (labels hidden for competition)\")\n",
    "print()\n",
    "\n",
    "# Your turn: Build the best model!\n",
    "# Tips:\n",
    "# 1. Feature engineering (create new features)\n",
    "# 2. Hyperparameter tuning\n",
    "# 3. Ensemble multiple models\n",
    "# 4. Use cross-validation\n",
    "\n",
    "print(\"Building competition model...\\n\")\n",
    "\n",
    "# Baseline model\n",
    "baseline_model = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "baseline_model.fit(X_train_kaggle, y_train_kaggle)\n",
    "baseline_pred = baseline_model.predict(X_test_kaggle)\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_test_kaggle, baseline_pred))\n",
    "\n",
    "print(f\"Baseline RMSE: {baseline_rmse:.4f}\\n\")\n",
    "\n",
    "# Your improved model (example)\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_kaggle)\n",
    "X_test_scaled = scaler.transform(X_test_kaggle)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid_competition = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [200, 500],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1]\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV for speed\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "xgb_competition = XGBRegressor(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb_competition,\n",
    "    param_grid_competition,\n",
    "    n_iter=20,  # Try 20 random combinations\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_scaled, y_train_kaggle)\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print()\n",
    "\n",
    "# Get best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate (in real Kaggle, you wouldn't have test labels)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_kaggle, test_predictions))\n",
    "test_r2 = r2_score(y_test_kaggle, test_predictions)\n",
    "\n",
    "print(\"COMPETITION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Baseline RMSE: {baseline_rmse:.4f}\")\n",
    "print(f\"Your RMSE:     {test_rmse:.4f}\")\n",
    "print(f\"Improvement:   {((baseline_rmse - test_rmse) / baseline_rmse * 100):.2f}%\")\n",
    "print(f\"Test R²:       {test_r2:.4f}\")\n",
    "print()\n",
    "\n",
    "# Create submission file (Kaggle format)\n",
    "submission = pd.DataFrame({\n",
    "    'Id': range(len(test_predictions)),\n",
    "    'Predicted': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created: submission.csv\")\n",
    "print(submission.head())\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Predicted vs Actual\n",
    "axes[0].scatter(y_test_kaggle, test_predictions, alpha=0.5, s=20)\n",
    "axes[0].plot([y_test_kaggle.min(), y_test_kaggle.max()],\n",
    "            [y_test_kaggle.min(), y_test_kaggle.max()],\n",
    "            'r--', lw=2, label='Perfect prediction')\n",
    "axes[0].set_xlabel('Actual Price ($100k)')\n",
    "axes[0].set_ylabel('Predicted Price ($100k)')\n",
    "axes[0].set_title(f'Competition Results (RMSE = {test_rmse:.4f})')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution comparison\n",
    "axes[1].hist(y_test_kaggle, bins=30, alpha=0.5, label='Actual', density=True)\n",
    "axes[1].hist(test_predictions, bins=30, alpha=0.5, label='Predicted', density=True)\n",
    "axes[1].set_xlabel('Price ($100k)')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].set_title('Distribution Comparison')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Clean up\n",
    "os.remove('submission.csv')\n",
    "\n",
    "print(\"\\n✓ Kaggle-style challenge complete!\")\n",
    "print(\"\\nNext steps to improve:\")\n",
    "print(\"- Feature engineering (polynomial features, interactions)\")\n",
    "print(\"- Ensemble multiple XGBoost models with different seeds\")\n",
    "print(\"- Stack XGBoost with other models (RF, GBM)\")\n",
    "print(\"- Use XGBoost's built-in cross-validation (xgb.cv)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challenge Problems\n",
    "\n",
    "### Challenge 1: Custom Objective Function\n",
    "\n",
    "Implement a custom objective function for XGBoost (e.g., Huber loss for robust regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss_objective(y_pred, dtrain):\n",
    "    \"\"\"\n",
    "    Custom Huber loss objective function.\n",
    "    \n",
    "    Huber loss is less sensitive to outliers than MSE.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    # Return gradient and hessian\n",
    "    pass\n",
    "\n",
    "# Use custom objective\n",
    "# xgb_custom = XGBRegressor(objective=huber_loss_objective)\n",
    "\n",
    "print(\"Challenge 1: Implement custom Huber loss objective!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: XGBoost with DMatrix\n",
    "\n",
    "Use XGBoost's native DMatrix API for maximum performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DMatrix (XGBoost's internal data structure)\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Train using native API\n",
    "# params = {\n",
    "#     'max_depth': 3,\n",
    "#     'eta': 0.1,\n",
    "#     'objective': 'binary:logistic',\n",
    "#     'eval_metric': 'logloss'\n",
    "# }\n",
    "\n",
    "# bst = xgb.train(params, dtrain, num_boost_round=100,\n",
    "#                 evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "#                 early_stopping_rounds=10)\n",
    "\n",
    "print(\"Challenge 2: Use XGBoost's DMatrix API for better performance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Multi-Output XGBoost\n",
    "\n",
    "Implement XGBoost for multi-output regression (predict multiple targets simultaneously)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Create multi-output dataset\n",
    "# from sklearn.datasets import make_regression\n",
    "# X, y = make_regression(n_samples=1000, n_features=10, n_targets=3, random_state=42)\n",
    "\n",
    "# Wrap XGBoost in MultiOutputRegressor\n",
    "# multi_xgb = MultiOutputRegressor(XGBRegressor(n_estimators=100))\n",
    "# multi_xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Challenge 3: Implement multi-output regression with XGBoost!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4: XGBoost Feature Interaction\n",
    "\n",
    "Use SHAP values to analyze feature interactions in XGBoost models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install SHAP: !pip install shap\n",
    "\n",
    "# import shap\n",
    "\n",
    "# explainer = shap.TreeExplainer(xgb_model)\n",
    "# shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# shap.summary_plot(shap_values, X_test, feature_names=feature_names)\n",
    "# shap.dependence_plot('feature_name', shap_values, X_test)\n",
    "\n",
    "print(\"Challenge 4: Use SHAP for interpretability!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 5: XGBoost with GPU Acceleration\n",
    "\n",
    "Train XGBoost using GPU for massive speedup (requires CUDA-enabled GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU for training\n",
    "# xgb_gpu = XGBClassifier(\n",
    "#     n_estimators=1000,\n",
    "#     tree_method='gpu_hist',  # Use GPU\n",
    "#     gpu_id=0,\n",
    "#     predictor='gpu_predictor'\n",
    "# )\n",
    "\n",
    "# xgb_gpu.fit(X_train, y_train)\n",
    "\n",
    "print(\"Challenge 5: Use GPU acceleration for faster training!\")\n",
    "print(\"Note: Requires CUDA-enabled GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reflection Questions\n",
    "\n",
    "1. **What makes XGBoost faster than traditional gradient boosting?**\n",
    "   - Think about parallelization and tree construction\n",
    "\n",
    "2. **When should you use early stopping vs setting a fixed n_estimators?**\n",
    "   - Consider computational cost and overfitting\n",
    "\n",
    "3. **How does scale_pos_weight help with imbalanced datasets?**\n",
    "   - What's the mathematical effect on the loss function?\n",
    "\n",
    "4. **Why are there three different feature importance metrics (weight, gain, cover)?**\n",
    "   - When would each be most useful?\n",
    "\n",
    "5. **How does XGBoost handle missing values automatically?**\n",
    "   - What's the algorithm's approach?\n",
    "\n",
    "6. **What's the relationship between learning_rate and n_estimators?**\n",
    "   - How do you balance them for best performance?\n",
    "\n",
    "7. **When would you choose XGBoost over Random Forest?**\n",
    "   - Consider accuracy, speed, interpretability, and tuning effort\n",
    "\n",
    "8. **How do regularization parameters (gamma, alpha, lambda) prevent overfitting?**\n",
    "   - What aspect of the model does each control?\n",
    "\n",
    "9. **Why is feature scaling often recommended but not required for XGBoost?**\n",
    "   - How do tree-based models differ from linear models?\n",
    "\n",
    "10. **What are the trade-offs of using XGBoost's native API vs sklearn wrapper?**\n",
    "    - Consider functionality, ease of use, and performance\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this exercise, you mastered:\n",
    "\n",
    "✓ XGBoost installation and basic usage  \n",
    "✓ Early stopping to prevent overfitting  \n",
    "✓ Systematic hyperparameter tuning  \n",
    "✓ Three types of feature importance (weight, gain, cover)  \n",
    "✓ XGBoost for regression tasks  \n",
    "✓ Handling imbalanced datasets with scale_pos_weight  \n",
    "✓ Comparing XGBoost with Random Forest and Gradient Boosting  \n",
    "✓ Model persistence (pickle, binary, JSON)  \n",
    "✓ Building complete production pipelines  \n",
    "✓ Kaggle-style competition workflows  \n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "- **XGBoost dominates structured data**: Industry standard for tabular data\n",
    "- **Regularization is built-in**: Less prone to overfitting than standard GBM\n",
    "- **Speed matters**: Highly optimized, supports parallel and GPU training\n",
    "- **Hyperparameter tuning is crucial**: Default params rarely optimal\n",
    "- **Early stopping saves time**: Automatically finds optimal tree count\n",
    "- **Feature importance aids interpretation**: Three metrics provide different insights\n",
    "- **Handles real-world challenges**: Missing values, imbalanced data, large datasets\n",
    "\n",
    "**XGBoost Hyperparameter Tuning Strategy:**\n",
    "\n",
    "1. **Start with defaults**: Establish baseline performance\n",
    "2. **Tune tree parameters**: max_depth, min_child_weight\n",
    "3. **Tune sampling**: subsample, colsample_bytree\n",
    "4. **Add regularization**: gamma, reg_alpha, reg_lambda\n",
    "5. **Fine-tune learning**: Lower learning_rate, increase n_estimators\n",
    "6. **Use early stopping**: Find optimal iteration automatically\n",
    "\n",
    "**When to Use XGBoost:**\n",
    "\n",
    "✓ Structured/tabular data  \n",
    "✓ Need high accuracy  \n",
    "✓ Kaggle competitions  \n",
    "✓ Large datasets  \n",
    "✓ Mixed feature types  \n",
    "✓ Missing values  \n",
    "✓ Imbalanced classes  \n",
    "\n",
    "**When NOT to Use XGBoost:**\n",
    "\n",
    "✗ Image/video data (use CNNs)  \n",
    "✗ Text data (use transformers)  \n",
    "✗ Need simple interpretability  \n",
    "✗ Very small datasets (<100 samples)  \n",
    "✗ Real-time inference critical (too slow)  \n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "- Practice on Kaggle competitions\n",
    "- Explore LightGBM and CatBoost (XGBoost alternatives)\n",
    "- Study SHAP for model interpretability\n",
    "- Learn XGBoost's distributed training (Dask, Spark)\n",
    "- Experiment with custom objective functions\n",
    "- Try GPU acceleration for large datasets\n",
    "\n",
    "**Resources:**\n",
    "\n",
    "- [XGBoost Documentation](https://xgboost.readthedocs.io/)\n",
    "- [XGBoost Parameters Explained](https://xgboost.readthedocs.io/en/latest/parameter.html)\n",
    "- [Kaggle XGBoost Tutorials](https://www.kaggle.com/learn/xgboost)\n",
    "- [SHAP for XGBoost](https://github.com/slundberg/shap)\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You now have comprehensive knowledge of XGBoost, one of the most powerful machine learning algorithms for structured data. Apply these skills to real-world problems and Kaggle competitions!\n",
    "\n",
    "**Need help?** Check the solution notebook or open an issue on [GitHub](https://github.com/jumpingsphinx/jumpingsphinx.github.io/issues)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
